{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010375f7-9b63-48fd-ba60-8b23f0ee9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 19:57:08.279 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:08.280 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:08.280 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:08.282 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:08.285 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:08.286 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-07-11 19:57:08.287 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:09.066 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ARMAN SINGH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-11 19:57:09.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:09.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:09.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:09.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-11 19:57:09.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Use this script as an integrated version if multipage app isn't used\n",
    "# Otherwise, split this into eda_dashboard.py, model_training.py, prediction_app.py, and Home.py\n",
    "\n",
    "st.set_page_config(page_title=\"Customer Churn App\", layout=\"wide\")\n",
    "page = st.sidebar.selectbox(\"Navigate\", [\"ðŸ  Home\", \"ðŸ“Š EDA\", \"âš™ï¸ Model Training\", \"ðŸ”® Predict\"])\n",
    "\n",
    "if page == \"ðŸ  Home\":\n",
    "    st.title(\"ðŸ“¦ Customer Churn Prediction App\")\n",
    "    st.markdown(\"\"\"\n",
    "    Welcome to the **Customer Churn Prediction** App! ðŸ‘‹\n",
    "\n",
    "    This multi-page Streamlit application allows you to:\n",
    "    - ðŸ“Š Explore your data (EDA)\n",
    "    - âš™ï¸ Train classification models with hyperparameter tuning\n",
    "    - ðŸ”® Predict churn from new data with any trained model\n",
    "\n",
    "    Use the sidebar to navigate between different modules.\n",
    "\n",
    "    ---\n",
    "    **Developed by Ayush Singh**\n",
    "    \"\"\")\n",
    "\n",
    "elif page == \"ðŸ“Š EDA\":\n",
    "    st.title(\"ðŸ“Š Customer Churn EDA Dashboard\")\n",
    "    uploaded_file = st.file_uploader(\"Upload your Churn CSV file\", type=[\"csv\"], key=\"eda\")\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "        df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
    "        if 'customerID' in df.columns:\n",
    "            df.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "        st.subheader(\"ðŸ“Œ Dataset Overview\")\n",
    "        st.write(df.head())\n",
    "\n",
    "        with st.expander(\"Show data summary\"):\n",
    "            st.write(df.describe(include='all'))\n",
    "            st.write(\"Missing Values:\")\n",
    "            st.write(df.isnull().sum())\n",
    "\n",
    "        chart_type = st.selectbox(\"Select Chart Type\", [\n",
    "            \"Churn Distribution\", \"Numerical Feature Distribution\", \"Boxplot by Churn\",\n",
    "            \"Categorical Countplot\", \"Correlation Heatmap\"])\n",
    "\n",
    "        if chart_type == \"Churn Distribution\":\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.countplot(data=df, x='Churn', palette='Set2', ax=ax)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        elif chart_type == \"Numerical Feature Distribution\":\n",
    "            num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "            num_feature = st.selectbox(\"Select numerical feature\", num_cols)\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.histplot(data=df, x=num_feature, kde=True, hue='Churn', palette='Set2', multiple='stack', ax=ax)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        elif chart_type == \"Boxplot by Churn\":\n",
    "            num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "            num_feature = st.selectbox(\"Select numerical feature for boxplot\", num_cols)\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.boxplot(data=df, x='Churn', y=num_feature, palette='Set1', ax=ax)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        elif chart_type == \"Categorical Countplot\":\n",
    "            cat_cols = [\n",
    "                'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "            cat_feature = st.selectbox(\"Select categorical feature\", cat_cols)\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.countplot(data=df, x=cat_feature, hue='Churn', palette='Set2', ax=ax)\n",
    "            plt.xticks(rotation=45)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        elif chart_type == \"Correlation Heatmap\":\n",
    "            corr_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'SeniorCitizen']\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            sns.heatmap(df[corr_cols].corr(), annot=True, cmap='coolwarm', ax=ax)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "elif page == \"âš™ï¸ Model Training\":\n",
    "    st.title(\"ðŸ¤– Customer Churn - Model Training & Evaluation\")\n",
    "    uploaded_file = st.file_uploader(\"Upload preprocessed churn CSV\", type=[\"csv\"], key=\"model\")\n",
    "    if uploaded_file is not None:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "        if 'customerID' in df.columns:\n",
    "            df.drop('customerID', axis=1, inplace=True)\n",
    "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "        df.fillna(0, inplace=True)\n",
    "        if 'Churn' not in df.columns:\n",
    "            st.error(\"Target column 'Churn' not found.\")\n",
    "            st.stop()\n",
    "\n",
    "        X = df.drop('Churn', axis=1)\n",
    "        y = df['Churn'].map({'Yes': 1, 'No': 0}) if df['Churn'].dtype == object else df['Churn']\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model_choice = st.selectbox(\"Select Classification Algorithm\", [\n",
    "            \"Logistic Regression\", \"KNN\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"Naive Bayes\", \"XGBoost\"])\n",
    "\n",
    "        scale_models = [\"Logistic Regression\", \"KNN\", \"SVM\"]\n",
    "        model_params = {\n",
    "            \"Logistic Regression\": (LogisticRegression(max_iter=1000), {\n",
    "                'model__C': [0.01, 0.1, 1, 10], 'model__solver': ['liblinear'] }),\n",
    "            \"KNN\": (KNeighborsClassifier(), {'model__n_neighbors': [3, 5, 7], 'model__weights': ['uniform', 'distance']}),\n",
    "            \"Decision Tree\": (DecisionTreeClassifier(), {'model__max_depth': [3, 5, 10, None], 'model__criterion': ['gini', 'entropy']}),\n",
    "            \"Random Forest\": (RandomForestClassifier(), {'model__n_estimators': [50, 100], 'model__max_depth': [None, 5, 10]}),\n",
    "            \"SVM\": (SVC(probability=True), {'model__C': [0.1, 1, 10], 'model__kernel': ['linear', 'rbf']}),\n",
    "            \"Naive Bayes\": (GaussianNB(), {}),\n",
    "            \"XGBoost\": (xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'), {\n",
    "                'model__n_estimators': [100], 'model__max_depth': [3, 6], 'model__learning_rate': [0.01, 0.1]})\n",
    "        }\n",
    "\n",
    "        clf, params = model_params[model_choice]\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ('model', clf)]) if model_choice in scale_models else Pipeline([('model', clf)])\n",
    "        with st.spinner(\"Training model with hyperparameter tuning...\"):\n",
    "            search = GridSearchCV(pipe, params, cv=3, scoring='accuracy', n_jobs=-1) if params else None\n",
    "            best_model = search.fit(X_train, y_train).best_estimator_ if search else pipe.fit(X_train, y_train)\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            y_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, \"predict_proba\") else y_pred\n",
    "\n",
    "            st.success(\"Training complete!\")\n",
    "            st.write(f\"**Accuracy:** {accuracy_score(y_test, y_pred):.4f}\")\n",
    "            st.write(f\"**F1 Score:** {f1_score(y_test, y_pred):.4f}\")\n",
    "            st.write(f\"**ROC AUC Score:** {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "            st.write(f\"**Best Parameters:** {search.best_params_ if search else 'Default'}\")\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "            ax.set_title('Confusion Matrix')\n",
    "            ax.set_xlabel('Predicted')\n",
    "            ax.set_ylabel('Actual')\n",
    "            st.pyplot(fig)\n",
    "\n",
    "elif page == \"ðŸ”® Predict\":\n",
    "    st.title(\"ðŸ”® Customer Churn - Prediction App\")\n",
    "    uploaded_file = st.file_uploader(\"Upload CSV File for Prediction\", type=[\"csv\"], key=\"predict\")\n",
    "    model_choice = st.selectbox(\"Select Model\", [\"Logistic Regression\", \"KNN\", \"Decision Tree\", \"Random Forest\", \"SVM\", \"Naive Bayes\", \"XGBoost\"])\n",
    "    \n",
    "    apply_scaling = st.checkbox(\"Apply Standard Scaling\", value=True)\n",
    "    apply_pca = st.checkbox(\"Apply PCA (for high-dimensional data)\")\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        df_pred = pd.read_csv(uploaded_file)\n",
    "\n",
    "        # Preprocessing\n",
    "        if 'customerID' in df_pred.columns:\n",
    "            df_pred.drop('customerID', axis=1, inplace=True)\n",
    "        if 'Churn' in df_pred.columns:\n",
    "            df_pred.drop('Churn', axis=1, inplace=True)\n",
    "\n",
    "        df_pred['TotalCharges'] = pd.to_numeric(df_pred['TotalCharges'], errors='coerce')\n",
    "        df_pred.fillna(0, inplace=True)\n",
    "\n",
    "        bin_map = {'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0}\n",
    "        for col in df_pred.columns:\n",
    "            if df_pred[col].nunique() == 2 and df_pred[col].dtype == object:\n",
    "                df_pred[col] = df_pred[col].map(bin_map)\n",
    "        \n",
    "        df_pred = pd.get_dummies(df_pred, drop_first=True)\n",
    "\n",
    "        # Feature alignment (simulate trained model structure)\n",
    "        model_features = df_pred.columns.tolist()  # Normally you'd load with joblib\n",
    "        df_pred = df_pred.reindex(columns=model_features, fill_value=0)\n",
    "\n",
    "        # Apply Scaling and PCA\n",
    "        if apply_scaling:\n",
    "            scaler = StandardScaler()\n",
    "            df_pred = scaler.fit_transform(df_pred)\n",
    "\n",
    "        if apply_pca:\n",
    "            pca = PCA(n_components=min(10, df_pred.shape[1]))\n",
    "            df_pred = pca.fit_transform(df_pred)\n",
    "\n",
    "        st.info(\"âš ï¸ Using simulated churn probabilities. Replace with real model.predict_proba in production.\")\n",
    "        \n",
    "        # ðŸ‘‰ Set decision threshold\n",
    "        threshold = st.slider(\"Set churn threshold\", 0.0, 1.0, 0.5, 0.01)\n",
    "\n",
    "        # ðŸ”„ Simulated probabilities (replace with model.predict_proba(X)[:,1] for real)\n",
    "        np.random.seed(42)\n",
    "        probs = np.random.rand(df_pred.shape[0])\n",
    "\n",
    "        # âœ… Predict churn based on threshold\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "\n",
    "        # ðŸ’¡ Confidence = probability of predicted class\n",
    "        confidence = np.where(preds == 1, probs * 100, (1 - probs) * 100)\n",
    "        status = np.where(preds == 1, \"Will Churn\", \"Will Not Churn\")\n",
    "\n",
    "        # ðŸ“‹ Results\n",
    "        result_df = pd.DataFrame({\n",
    "            \"Churn Probability\": probs.round(4),\n",
    "            \"Predicted Label\": preds,\n",
    "            \"Status\": status,\n",
    "            \"Confidence (%)\": confidence.round(2)\n",
    "        })\n",
    "\n",
    "        st.subheader(\"ðŸ“Š Prediction Results\")\n",
    "        st.write(result_df.head())\n",
    "\n",
    "        # ðŸ“¥ Download\n",
    "        csv = result_df.to_csv(index=False).encode()\n",
    "        st.download_button(\"ðŸ“¥ Download Predictions\", csv, \"predictions.csv\", \"text/csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeeeb36-607b-4b3d-8090-06ee6e802744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d75ff-c9fb-45f0-b972-72b6b63fb5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
